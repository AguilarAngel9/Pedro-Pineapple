{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory\n",
    "\n",
    "**Author: @THEFFTKID**\n",
    "\n",
    "So far, we have trained sensation-based models to tune the various parameters. In order to perform a better search over the hyperparameter space we use the Hyperopt library, seeking to minimize the negative of the acurracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aargaez/downloads/Pedro-Pineapple/forecasting\n"
     ]
    }
   ],
   "source": [
    "cd ~/downloads/Pedro-Pineapple/forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag experiment.\n",
    "new_experiment = True\n",
    "# Name\n",
    "experiment_name = \"A2C\"\n",
    "# Description.\n",
    "experiment_description = (\n",
    "    \"Index - Stock forecasting project.\"\n",
    "    \"This experiment contains the models using AC2 policy.\"\n",
    ")\n",
    "# Tags\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Continous update policy\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_experiment:\n",
    "    # Creates the MLflow experiment.\n",
    "    produce_experiment = client.create_experiment(\n",
    "        name=experiment_name,\n",
    "        tags=experiment_tags\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 21:04:00.275832: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 21:04:02.491951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 21:04:07.480848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import environments\n",
    "import numpy as np\n",
    "import evaluation\n",
    "import utils\n",
    "\n",
    "from dynamic_threshold import define_threshold\n",
    "from stable_baselines3 import A2C\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List\n",
    "from json import dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fluent API to set the tracking uri and the active experiment.\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Sets the current active experiment to the \"index_forecast\" experiment and returns the experiment metadata.\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"a2c_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experiment(parameters: Dict[str, Any], features: List[str]):\n",
    "    \"\"\"\n",
    "    Wrapper function for MLflow model versioning\n",
    "    \"\"\"\n",
    "    # Read data.\n",
    "    data = pd.read_csv(filepath_or_buffer=parameters['data_path'])\n",
    "    # Cast columns.\n",
    "    data.columns = data.columns.str.lower()\n",
    "\n",
    "    data['labels'], data['perc_relative_diff'] = evaluation.create_labels(\n",
    "        x=data['close'],\n",
    "        labels=[0, 1, 2],\n",
    "        perc_bounds=[\n",
    "            parameters['lower_threshold'],\n",
    "            parameters['upper_threshold']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Split dataset into train and test.\n",
    "    df_train, df_test = evaluation.data_splitter(\n",
    "        raw_data=data,\n",
    "        proportion=parameters['proportion']\n",
    "    )\n",
    "\n",
    "    # Create the environment.\n",
    "    env = environments.Forecasting(\n",
    "        df=df_train,\n",
    "        series_features=features,\n",
    "        window_size=parameters['window_size'],\n",
    "        lower_threshold=parameters['lower_threshold'],\n",
    "        upper_threshold=parameters['upper_threshold']\n",
    "    )\n",
    "\n",
    "    # Train environment.\n",
    "    model = A2C('MlpPolicy', env, verbose=0)\n",
    "\n",
    "    # Train model with MLflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Learn.\n",
    "        model.learn(total_timesteps=parameters['time_steps'])\n",
    "\n",
    "        # Initialize a new environment with test-set.\n",
    "        env_test = environments.Forecasting(\n",
    "            df=df_test,\n",
    "            series_features=features,\n",
    "            window_size=parameters['window_size'],\n",
    "            lower_threshold=parameters['lower_threshold'],\n",
    "            upper_threshold=parameters['upper_threshold']\n",
    "        )\n",
    "\n",
    "        # Reset environment.\n",
    "        observation, info = env_test.reset(\n",
    "            upper_threshold=env.up_threshold,\n",
    "            lower_threshold=env.low_threshold\n",
    "        )\n",
    "\n",
    "        while True: \n",
    "            observation = observation[np.newaxis, ...]\n",
    "            action, states = model.predict(observation)\n",
    "            observation, rewards, done, truncated, info = env_test.step(action)\n",
    "            if done or truncated:\n",
    "                print('info', info, '\\n')\n",
    "                break\n",
    "        \n",
    "        y_true = df_test['labels'].to_numpy()[parameters['window_size'] + 1:]\n",
    "        y_pred = np.concatenate(env_test.actions_history)\n",
    "\n",
    "        performance = evaluation.evaluation_metrics(\n",
    "            y_true=y_true,\n",
    "            y_pred=y_pred,\n",
    "            target_names=['down', 'no', 'up']\n",
    "        )\n",
    "\n",
    "        accuracy = performance['accuracy']\n",
    "\n",
    "        # print(dumps(performance, indent=4))\n",
    "\n",
    "        # Logging params and metrics to MLflow.\n",
    "        metrics = utils.flatten_dict(d=performance)\n",
    "\n",
    "        # Log the parameters used for the model fit.\n",
    "        # mlflow.log_params(params=dataclasses.asdict(parameters))\n",
    "        mlflow.log_params(params=parameters)\n",
    "\n",
    "        # Log the error metrics that were calculated during validation.\n",
    "        mlflow.log_metrics(metrics=metrics)\n",
    "\n",
    "        # TODO: Log an instance of the trained model for later use.\n",
    "        \n",
    "        return {\"loss\": -accuracy, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run.\n",
    "    result = train_experiment(\n",
    "        parameters=params,\n",
    "        features=[\n",
    "            'open',\n",
    "            'high',\n",
    "            'low',\n",
    "            'volume_roc',\n",
    "            'n10_rolling_mean',\n",
    "            'n10_weighted_rolling_mean',\n",
    "            'momentum',\n",
    "            'close',\n",
    "            'nday_tendency_removal'\n",
    "        ]\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space.\n",
    "space = {\n",
    "    \"time_steps\":  hp.randint(\"time_steps\", 500, 1500),\n",
    "    \"window_size\": hp.randint(\"window_size\", 10, 15),\n",
    "    \"lower_threshold\": hp.uniform(\"lower_threshold\", 0.4, 0.5),\n",
    "    \"upper_threshold\": hp.uniform(\"upper_threshold\", 0.5, 0.6),\n",
    "    \"proportion\": hp.uniform(\"proportion\", 0.7, 0.9),\n",
    "    \"data_path\": hp.choice(\"data_path\", (\n",
    "        '/home/aargaez/downloads/Pedro-Pineapple/data/SPY_20022006.csv',\n",
    "        '/home/aargaez/downloads/Pedro-Pineapple/data/SPY_20122016.csv',\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info                                                  \n",
      "{'total_reward': 70.25005199999998}                   \n",
      "info                                                                              \n",
      "{'total_reward': 69.10005900000002}                                               \n",
      "info                                                                              \n",
      "{'total_reward': 85.2800149999999}                                               \n",
      "info                                                                             \n",
      "{'total_reward': 103.54997499999999}                                             \n",
      " 33%|███▎      | 4/12 [00:21<00:40,  5.03s/trial, best loss: -0.4474885844748858]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aargaez/downloads/Pedro-Pineapple/venvpp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "/home/aargaez/downloads/Pedro-Pineapple/venvpp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "/home/aargaez/downloads/Pedro-Pineapple/venvpp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info                                                                             \n",
      "{'total_reward': 138.50998099999984}                                             \n",
      "info                                                                              \n",
      "{'total_reward': 187.11005200000002}                                              \n",
      "info                                                                              \n",
      "{'total_reward': 60.00001200000003}                                               \n",
      "info                                                                              \n",
      "{'total_reward': 57.77001900000006}                                               \n",
      "info                                                                              \n",
      "{'total_reward': 93.93000799999984}                                               \n",
      "info                                                                              \n",
      "{'total_reward': 142.8599719999999}                                               \n",
      "info                                                                               \n",
      "{'total_reward': 73.34000900000007}                                                \n",
      "info                                                                               \n",
      "{'total_reward': 65.67006499999995}                                                \n",
      "100%|██████████| 12/12 [00:56<00:00,  4.67s/trial, best loss: -0.45604395604395603]\n",
      "Best parameters: {'data_path': 0, 'lower_threshold': 0.4665489815729599, 'proportion': 0.8432552285561149, 'time_steps': 638, 'upper_threshold': 0.5577967212410858, 'window_size': 12}\n",
      "Best rmse: -0.45604395604395603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aargaez/downloads/Pedro-Pineapple/venvpp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "/home/aargaez/downloads/Pedro-Pineapple/venvpp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "/home/aargaez/downloads/Pedro-Pineapple/venvpp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run for save the model.\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt.\n",
    "    trials = Trials()\n",
    "\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=12,\n",
    "        trials=trials,\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    # mlflow.log_params(best)\n",
    "    # mlflow.log_metric(\"rmse\", best_run[\"loss\"])\n",
    "    # mlflow.tensorflow.log_model(best[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Best parameters.\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best rmse: {best_run['loss']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
